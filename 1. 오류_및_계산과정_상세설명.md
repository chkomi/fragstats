## 원본 스크립트의 오류 및 수정된 분석 과정 상세 설명

사용자님의 요청에 따라, 기존 분석(`entropy_weight_model.py`)에 왜 오류가 있었는지, 그리고 제가 새로 수행한 분석(`advanced_entropy_model.py`)은 어떤 과정을 거쳤는지 구체적인 계산 과정과 함께 상세히 설명해 드리겠습니다.

---

### 파트 1: 원본 스크립트의 결정적 오류 상세 설명

오류의 핵심은 **종합 점수를 계산하는 로직**에 있었습니다.

#### 1. 문제의 코드

원본 스크립트(`entropy_weight_model.py`)의 `calculate_comprehensive_score` 함수 내에는 다음과 같은 코드가 있습니다.

```python
# (원본 스크립트의 일부)
def calculate_comprehensive_score(data_point, ...):
    # ...
    for indicator, info in indicator_weights.items():
        val = safe_float(data_point['data'].get(indicator))
        if val is not None:
            # ▼▼▼ 바로 이 부분이 결정적 오류입니다 ▼▼▼
            normalized = normalize_data([val], direction)[0] 
            
            if normalized is not None:
                score += normalized * info['weight']
    # ...
    return final_score, indicator_score
```

#### 2. 무엇이 잘못되었는가?

위 코드의 `normalize_data([val], direction)[0]` 부분은 **전체 데이터와 비교하여 정규화(Normalization)를 하는 것이 아니라, 값 하나하나를 자기 자신과 비교하여 정규화**하고 있습니다.

정규화의 목적은 **서로 다른 범위의 값들을 0과 1 사이의 동일한 척도로 바꾸어 비교 가능하게 만드는 것**입니다. 예를 들어, 100점 만점의 시험 점수와 4.5점 만점의 학점을 같은 선상에서 비교하려면 정규화가 필요합니다. 이를 위해서는 **전체 학생의 점수 분포(최소값, 최대값)를 알아야 합니다.**

하지만 위 코드는 단 하나의 값 `[val]`을 정규화 함수에 넣습니다. 이 경우, 리스트 안에는 값이 하나뿐이므로 `최소값 = 최대값 = val`이 됩니다.

Min-Max 정규화 공식은 `(값 - 최소값) / (최대값 - 최소값)` 입니다.
여기에 대입하면 `(val - val) / (val - val)` 즉, `0 / 0` 이라는 수학적으로 정의되지 않는 상황이 발생합니다. 원본 코드는 이 경우 0.5를 반환하도록 되어 있었습니다.

결과적으로, **모든 지표의 모든 값들이 데이터의 실제 크기와 상관없이 항상 0.5라는 동일한 정규화 값**을 갖게 됩니다.

#### 3. 쉬운 예시

학생 A, B, C의 시험 점수가 각각 90점, 60점, 100점이라고 가정해 보겠습니다.

*   **잘못된 방식 (원본 스크립트):**
    *   학생 A의 점수 `[90]`을 정규화 → 최소=90, 최대=90 → `(90-90)/(90-90)` → 0.5 반환
    *   학생 B의 점수 `[60]`을 정규화 → 최소=60, 최대=60 → `(60-60)/(60-60)` → 0.5 반환
    *   학생 C의 점수 `[100]`을 정규화 → 최소=100, 최대=100 → `(100-100)/(100-100)` → 0.5 반환
    *   **결과:** 모든 학생의 점수가 0.5가 되어 누가 더 잘했는지 전혀 구별할 수 없습니다. `엔트로피가중치_평가모델_결과.txt`에서 모든 '지표점수'가 50점으로 동일하게 나온 것이 바로 이 때문입니다.

*   **올바른 방식 (수정된 분석):**
    *   전체 점수 `[90, 60, 100]`을 정규화 → 최소=60, 최대=100
    *   학생 A: `(90-60)/(100-60)` = 30/40 = **0.75**
    *   학생 B: `(60-60)/(100-60)` = 0/40 = **0.0**
    *   학생 C: `(100-60)/(100-60)` = 40/40 = **1.0**
    *   **결과:** 각 학생의 상대적 위치가 0과 1 사이의 값으로 명확하게 표현됩니다.

이 오류로 인해 원본 스크립트의 종합 점수는 데이터의 특성을 전혀 반영하지 못한, 의미 없는 결과가 된 것입니다.

---

### 파트 2: 수정된 분석 (`advanced_entropy_model.py`)의 상세 계산 과정

제가 수정한 스크립트는 위와 같은 오류를 바로잡고, 사용자님의 요청에 따라 모든 지표를 사용하여 더욱 정교하고 검증 가능하게 만들어졌습니다. 전체 과정은 다음과 같습니다.

#### **1단계: 모든 데이터 통합 (Data Aggregation)**

-   **목표:** 8개 평가 대상(`hwasun_infra`, `naju_pibok` 등) 각각에 대해, 3개 레벨의 모든 지표 값을 하나의 데이터셋으로 통합합니다.
-   **과정:**
    1.  `*_class.txt` 파일 4개를 읽어, 각 평가 대상에 해당하는 31개의 **Class 레벨** 지표 값을 추출합니다. (`CLS_` 접두사 부여)
    2.  `*_land.txt` 파일 4개를 읽어, 각 평가 대상의 경관에 해당하는 19개의 **Land 레벨** 지표 값을 가져옵니다. (`LND_` 접두사 부여)
    3.  `*_patch.txt` 파일들을 읽어, 각 평가 대상에 해당하는 패치들의 데이터를 필터링한 후, 8개 **Patch 레벨** 지표 각각의 **평균값**을 계산합니다. (`PATCH_*_MN` 접두사 부여)
-   **결과:** 8개의 평가 대상 각각이 약 58개(`31+19+8`)의 통합된 지표 값을 갖는 데이터 구조가 완성됩니다. (`aggregated_data.json` 파일)

#### **2단계: 데이터 행렬 구축 및 지표 방향성 정의**

-   **목표:** 엔트로피 분석을 위한 기본 테이블(8행 × 58열)을 만들고, 각 지표의 좋고 나쁨을 정의합니다.
-   **과정:**
    1.  **행렬 구축:** 1단계에서 통합된 데이터를 바탕으로, 행(row)은 8개 평가 대상, 열(column)은 58개 지표로 구성된 데이터 매트릭스를 만듭니다.
    2.  **방향성 정의:** 58개 모든 지표에 대해, 값이 클수록 좋은지(`positive`), 작을수록 좋은지(`negative`)를 정의합니다. 예를 들어, 농지 면적을 나타내는 `CLS_AREA_MN`은 `positive`이지만, 파편화 정도를 나타내는 `CLS_NP`(패치 수)는 `negative`입니다. 이 정의는 FRAGSTATS 지표의 의미에 기반합니다.

#### **3단계: 데이터 정규화 (Normalization)**

-   **목표:** 단위와 범위가 제각각인 58개 지표들을 모두 0과 1 사이의 동일한 스케일로 변환하여 비교 가능하게 만듭니다.
-   **과정:** 2단계에서 정의한 방향성에 따라 다음 공식을 **각 열(지표)별로** 적용합니다.
    -   `positive` 지표: `정규화 값 = (원본 값 - 해당 지표의 최소값) / (해당 지표의 최대값 - 해당 지표의 최소값)`
    -   `negative` 지표: `정규화 값 = (해당 지표의 최대값 - 원본 값) / (해당 지표의 최대값 - 해당 지표의 최소값)`
-   **결과:** 모든 값이 0~1 사이로 변환된 정규화 행렬이 생성됩니다. 1에 가까울수록 해당 지표 측면에서 '바람직함'을 의미합니다.

#### **4단계: 엔트로피 및 지표별 가중치 계산**

-   **목표:** 각 지표가 평가에서 얼마나 중요한지를 나타내는 객관적인 가중치를 계산합니다.
-   **과정:**
    1.  **비중(P) 계산:** 정규화 행렬의 각 열(지표)에서, 각 값(8개)이 열의 총합에서 차지하는 비중을 계산합니다.
    2.  **엔트로피(E) 계산:** 각 지표별로 `E = -k * Σ(P * ln(P))` 공식을 사용하여 엔트로피를 계산합니다.
        -   어떤 지표의 값들이 모두 비슷하면(예: 모든 지역이 0.5), 엔트로피는 1에 가깝게 나옵니다. 이는 해당 지표가 지역을 변별할 힘이 없다는 의미입니다.
        -   값들의 차이가 크면 엔트로피는 0에 가깝게 나오고, 변별력이 높다는 의미입니다.
    3.  **분산도(D) 계산:** `D = 1 - E`를 계산합니다. 엔트로피와 반대 개념으로, 클수록 정보량이 많고 중요합니다.
    4.  **최종 가중치(W) 계산:** 각 지표의 분산도를 모든 지표의 분산도 총합으로 나누어 최종 가중치를 계산합니다. `W = D / ΣD`. (모든 가중치의 합은 1)

#### **5단계: 종합 점수 산출**

-   **목표:** 계산된 가중치를 이용하여 8개 평가 대상 각각의 최종 점수를 계산합니다.
-   **과정:** 각 평가 대상(행)에 대해, **(3단계의 정규화 값) × (4단계의 최종 가중치)**를 모든 지표에 걸쳐 합산합니다.
    -   `종합 점수 = Σ (지표j의 정규화 값 × 지표j의 가중치) * 100`
-   **결과:** `naju_nongeup: 74.08점`, `hwasun_pibok: 28.03점` 등과 같이 각 평가 대상의 농업적 가치를 정량적으로 나타내는 최종 점수가 도출됩니다.

이 모든 과정과 중간 계산 결과는 `종합_평가_방법론.md` 파일에 투명하게 기록되어 있어, 언제든 검증할 수 있습니다.
